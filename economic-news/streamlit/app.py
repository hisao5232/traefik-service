import os
import streamlit as st
import requests
import yfinance as yf
import pandas as pd
import plotly.graph_objs as go
from datetime import datetime

API_KEY = os.getenv("API_SECRET_KEY")

st.title("æ—¥çµŒå¹³å‡ã¨ãƒ‰ãƒ«å††ãƒ¬ãƒ¼ãƒˆã®ãƒãƒ£ãƒ¼ãƒˆ")

# --- æ—¥çµŒå¹³å‡ãƒãƒ£ãƒ¼ãƒˆ ---
nikkei_ticker = "^N225"
period = st.selectbox("æœŸé–“ã‚’é¸æŠ", ["5d", "1mo", "3mo", "6mo", "1y", "2y"], index=1)

nikkei_data = yf.download(nikkei_ticker, period=period, interval="1d")
if isinstance(nikkei_data.columns, pd.MultiIndex):
    nikkei_data.columns = nikkei_data.columns.get_level_values(0)

# ã“ã“ã«æ˜¨æ—¥ã®æ—¥çµŒå¹³å‡ã®çµ‚å€¤ã‚’è¡¨ç¤ºã€€H2ã‚¿ã‚°ãã‚‰ã„ã®å¤§ãã•
if not nikkei_data.empty and "Close" in nikkei_data.columns:
    # æœ€å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆï¼ˆé€šå¸¸ã¯ã€Œæ˜¨æ—¥ã€ã®çµ‚å€¤ï¼‰ã‚’å–å¾—
    last_close_nikkei = nikkei_data["Close"].iloc[-1]
    # H2ã‚¿ã‚°ãã‚‰ã„ã®å¤§ãã•ã§è¡¨ç¤º
    st.markdown(f"## æ˜¨æ—¥ã®æ—¥çµŒå¹³å‡çµ‚å€¤: {last_close_nikkei:,.2f}")
else:
    st.info("çµ‚å€¤ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

st.subheader(f"{nikkei_ticker} ã®ãƒ­ãƒ¼ã‚½ã‚¯è¶³ãƒãƒ£ãƒ¼ãƒˆ")
if not nikkei_data.empty and all(col in nikkei_data.columns for col in ["Open", "High", "Low", "Close"]):
    fig_nikkei = go.Figure(
        data=[
            go.Candlestick(
                x=nikkei_data.index,
                open=nikkei_data["Open"],
                high=nikkei_data["High"],
                low=nikkei_data["Low"],
                close=nikkei_data["Close"],
                name="æ—¥çµŒå¹³å‡"
            )
        ]
    )
    fig_nikkei.update_layout(
        xaxis_title="æ—¥ä»˜",
        yaxis_title="ä¾¡æ ¼",
        xaxis_rangeslider_visible=False,
        yaxis=dict(tickformat=",.0f")  # 3æ¡ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§æ•´æ•°è¡¨ç¤º
    )
    st.plotly_chart(fig_nikkei)
else:
    st.warning("æ—¥çµŒå¹³å‡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# --- ãƒ‰ãƒ«å††ãƒ¬ãƒ¼ãƒˆã®æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ• ---
usd_jpy_ticker = "JPY=X"
usd_jpy_data = yf.download(usd_jpy_ticker, period=period, interval="1d")
if isinstance(usd_jpy_data.columns, pd.MultiIndex):
    usd_jpy_data.columns = usd_jpy_data.columns.get_level_values(0)

# ã“ã“ã«æ˜¨æ—¥ã®ãƒ‰ãƒ«å††ã®çµ‚å€¤ã‚’è¡¨ç¤ºã€€H2ã‚¿ã‚°ãã‚‰ã„ã®å¤§ãã•
if not usd_jpy_data.empty and "Close" in usd_jpy_data.columns:
    # æœ€å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆï¼ˆé€šå¸¸ã¯ã€Œæ˜¨æ—¥ã€ã®çµ‚å€¤ï¼‰ã‚’å–å¾—
    last_close_fx = usd_jpy_data["Close"].iloc[-1]
    # H2ã‚¿ã‚°ãã‚‰ã„ã®å¤§ãã•ã§è¡¨ç¤º
    st.markdown(f"## æ˜¨æ—¥ã®ãƒ‰ãƒ«å††çµ‚å€¤: {last_close_fx:,.3f}å††")
else:
    st.info("çµ‚å€¤ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

st.subheader(f"{usd_jpy_ticker} ã®çµ‚å€¤æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•")
if not usd_jpy_data.empty and "Close" in usd_jpy_data.columns:
    fig_fx = go.Figure(
        data=[
            go.Scatter(
                x=usd_jpy_data.index,
                y=usd_jpy_data["Close"],
                mode="lines+markers",
                name="USD/JPY"
            )
        ]
    )
    fig_fx.update_layout(
        xaxis_title="æ—¥ä»˜",
        yaxis_title="ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆ"
    )
    st.plotly_chart(fig_fx)
else:
    st.warning("ãƒ‰ãƒ«å††ãƒ¬ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªãƒ¼ãƒ€ãƒ¼", page_icon="ğŸ“°", layout="wide")

# APIã®URL (Dockerãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†…ã§ã¯ãªãã€ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªURLã‚’æŒ‡å®š)
API_URL = "https://stock-news-api.go-pro-world.net/news"

st.title("ğŸ“° çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.caption("æ—¥çµŒãƒ“ã‚¸ãƒã‚¹ãƒ»Yahooãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»æ±æ´‹çµŒæ¸ˆã‹ã‚‰æœ€æ–°è¨˜äº‹ã‚’å–å¾—ã—ã¦ã„ã¾ã™")

# ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ã—ã¦é«˜é€ŸåŒ–ï¼‰
@st.cache_data(ttl=600)  # 10åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def fetch_news():
    try:
        # ãƒ˜ãƒƒãƒ€ãƒ¼ã«APIã‚­ãƒ¼ã‚’ã‚»ãƒƒãƒˆ
        headers = {"X-API-KEY": API_KEY}
        response = requests.get(API_URL, headers=headers, timeout=10)
        response.raise_for_status()

        data = response.json()
        df = pd.DataFrame(data)
        # æ—¥æ™‚ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
        df['scraped_at'] = pd.to_datetime(df['scraped_at']).dt.strftime('%Y/%m/%d %H:%M')
        return df
    except Exception as e:
        st.error(f"APIã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

df = fetch_news()

if not df.empty:
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ã”ã¨ã«ã‚¿ãƒ–ã‚’ä½œæˆ
    sources = ["ã™ã¹ã¦"] + list(df['source'].unique())
    tabs = st.tabs(sources)

    for i, source in enumerate(sources):
        with tabs[i]:
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered_df = df if source == "ã™ã¹ã¦" else df[df['source'] == source]
            
            # è¨˜äº‹ã‚’ãƒªã‚¹ãƒˆè¡¨ç¤º
            for _, row in filtered_df.iterrows():
                with st.container():
                    col1, col2 = st.columns([0.8, 0.2])
                    with col1:
                        st.markdown(f"### [{row['title']}]({row['url']})")
                        st.caption(f"ã‚½ãƒ¼ã‚¹: {row['source']} | å–å¾—æ—¥æ™‚: {row['scraped_at']}")
                    with col2:
                        # ãƒªãƒ³ã‚¯ãƒœã‚¿ãƒ³
                        st.link_button("è¨˜äº‹ã‚’é–‹ã", row['url'])
                    st.divider()
else:
    st.info("ç¾åœ¨è¡¨ç¤ºã§ãã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ãŒå‹•ä½œã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
